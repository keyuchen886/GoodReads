{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from scipy import spatial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first read the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/book_embedding.firefire', \"rb\") as file:\n",
    "    book_embedding = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = {v['name']:k for k,v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_simi(book_id, num_display):\n",
    "    embedding = data[book_id]['embedding']\n",
    "    name = data[book_id]['name']\n",
    "    \n",
    "    \n",
    "    #get all names\n",
    "    all_names = [v['name'] for k,v in data.items()]\n",
    "\n",
    "    \n",
    "    \n",
    "    distance = np.array(  [ 1 - spatial.distance.cosine(embedding, v['embedding']) for k,v in data.items() ] )\n",
    "    result = distance.argsort()[-num_display:][::-1]\n",
    "    recommend_names =   [all_names[i] for i in result] \n",
    "    print(\"the book is \"+recommend_names[0])\n",
    "    for i in range(1,len(recommend_names)):\n",
    "        print('we recommend this book '+recommend_names[i])\n",
    "    return(recommend_names)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the book is Batman & Superman: World's Finest - The Silver Age Vol. 1\n",
      "we recommend this book Marvel Masterworks: The Mighty Thor - Volume 4\n",
      "we recommend this book Martian Manhunter\n",
      "we recommend this book The Green Lantern Archives, Vol. 4\n",
      "we recommend this book The Joker: The Clown Prince of Crime\n",
      "we recommend this book The Superman Chronicles, Vol. 9\n",
      "we recommend this book The Children's Crusade #2 (2 of 2)\n",
      "we recommend this book New Gods: Hordes\n",
      "we recommend this book Marvel Masterworks: The Amazing Spider-Man - Volume 7\n",
      "we recommend this book Marvel Masterworks: Golden Age Marvel Comics, Vol. 1\n",
      "we recommend this book Marvel Masterworks: Golden Age Daring Mystery, Vol. 2\n",
      "we recommend this book Marvel Masterworks: Golden Age Daring Mystery, Vol. 1\n",
      "we recommend this book Marvel Masterworks: Atlas Era Black Knight/Yellow Claw, Vol. 1\n",
      "we recommend this book Olive Peril\n",
      "we recommend this book Marvel Masterworks: Captain America - Volume 2\n",
      "we recommend this book Marvel Masterworks: The Invincible Iron Man, Vol. 4\n",
      "we recommend this book Marvel Masterworks: Daredevil - Volume 3\n",
      "we recommend this book Marvel Masterworks vol. 30: The Mighty Thor, Vol. 3\n",
      "we recommend this book Marvel Masterworks: Atlas Era Journey into Mystery, Vol. 1\n",
      "we recommend this book The Superman Chronicles, Vol. 10\n"
     ]
    }
   ],
   "source": [
    "a = check_simi('31616110' , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the book is 乙嫁語り 1 (Otoyomegatari #1)\n",
      "we recommend this book Gepetto\n",
      "we recommend this book City Hunter Volume 4\n",
      "we recommend this book Assassination Classroom Vol. 14\n",
      "we recommend this book City Hunter Volume 5\n",
      "we recommend this book 名探偵コナン 36 (Detective Conan #36)\n",
      "we recommend this book 3 Potong Kisah Repot\n",
      "we recommend this book Assassination Classroom Vol. 10\n",
      "we recommend this book Ajin: Demi-Human, Volume 4 (Ajin: Demi-Human, #4)\n",
      "we recommend this book 夏目友人帳 1\n",
      "we recommend this book Ajin Vol. 8 (Ajin: Demi-Human, #8)\n",
      "we recommend this book Bintang-bintang untuk Iznogoud (Iznogoud, #5)\n",
      "we recommend this book Romance of Three Kingdom 4 : Bersiap Melakukan Lompatan\n",
      "we recommend this book Assassination Classroom Vol. 16\n",
      "we recommend this book Black Butler 23\n",
      "we recommend this book バクマン。 13\n",
      "we recommend this book 結界師 1\n",
      "we recommend this book A Chef of Nobunaga Vol. 8\n",
      "we recommend this book The Gamer, Season 2\n",
      "we recommend this book Ajin: Demi-Human, Volume 6 (Ajin: Demi-Human, #6)\n"
     ]
    }
   ],
   "source": [
    "a = check_simi('7673573' , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the book is Fairy Tail Vol. 46\n",
      "we recommend this book Naruto Vol. 60\n",
      "we recommend this book Fullmetal Alchemist Vol. 17\n",
      "we recommend this book Fullmetal Alchemist Vol. 16\n",
      "we recommend this book Fullmetal Alchemist Vol. 15\n",
      "we recommend this book Wild Base Ballers Vol. 4\n",
      "we recommend this book Naruto Vol. 67\n",
      "we recommend this book The Law Of Ueki 9\n",
      "we recommend this book Naruto Vol. 22: Tensei...!!\n",
      "we recommend this book Naruto Vol. 51: Sasuke vs Danzo!!\n",
      "we recommend this book Naruto Vol. 13: Ujian Chuunin, Selesai...!!\n",
      "we recommend this book Naruto Vol. 45: Medan Perang Konoha\n",
      "we recommend this book Naruto Vol. 10: A Great Ninja...!\n",
      "we recommend this book Naruto Vol. 25: Itachi dan Sasuke\n",
      "we recommend this book Wild Base Ballers Vol. 1\n",
      "we recommend this book Attack on Titan Vol. 6\n",
      "we recommend this book Naruto Vol. 28: Naruto's Return\n",
      "we recommend this book Naruto Vol. 62\n",
      "we recommend this book Naruto Vol. 34: Reunion...!\n",
      "we recommend this book One Piece Vol. 78\n"
     ]
    }
   ],
   "source": [
    "a = check_simi('35665524' , 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "1. From the above examples, we see that books shows similarity in their cosine distance. For Japanese comics, the nearest of them are all about japanese comics. Bataman will also have other super heros in recommendation.\n",
    "2. We can also include this as feature in recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/user_embedding.firefire', \"rb\") as file:\n",
    "    user_embedding = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's prepare our training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(record, user_embedding, book_embedding):\n",
    "    user_id = record['user_id']\n",
    "    book_id = record['book_id']\n",
    "    features = user_embedding[user_id] + book_embedding[book_id]['embedding']\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/goodreads_reviews_comics_graphic.json','r') as file:\n",
    "    for review in file:\n",
    "        record = json.loads(review)\n",
    "        try:\n",
    "            X.append( get_embeddings(record, user_embedding, book_embedding) )\n",
    "            y.append( record['rating'] )\n",
    "        except:\n",
    "            continue\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523699"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.083170</td>\n",
       "      <td>-0.043354</td>\n",
       "      <td>0.076106</td>\n",
       "      <td>0.040648</td>\n",
       "      <td>-0.037274</td>\n",
       "      <td>-0.071351</td>\n",
       "      <td>0.074718</td>\n",
       "      <td>0.100185</td>\n",
       "      <td>-0.035602</td>\n",
       "      <td>-0.064168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109340</td>\n",
       "      <td>0.252012</td>\n",
       "      <td>-0.828429</td>\n",
       "      <td>0.283238</td>\n",
       "      <td>0.844313</td>\n",
       "      <td>-0.335749</td>\n",
       "      <td>0.259507</td>\n",
       "      <td>0.261004</td>\n",
       "      <td>0.393101</td>\n",
       "      <td>-0.043140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.099338</td>\n",
       "      <td>-0.070405</td>\n",
       "      <td>0.205419</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>-0.094676</td>\n",
       "      <td>-0.174042</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>-0.113713</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186319</td>\n",
       "      <td>-0.279245</td>\n",
       "      <td>-0.044980</td>\n",
       "      <td>0.132863</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>-0.043891</td>\n",
       "      <td>0.665636</td>\n",
       "      <td>-0.470371</td>\n",
       "      <td>-0.014240</td>\n",
       "      <td>0.328362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.099338</td>\n",
       "      <td>-0.070405</td>\n",
       "      <td>0.205419</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>-0.094676</td>\n",
       "      <td>-0.174042</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>-0.113713</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356585</td>\n",
       "      <td>-0.104044</td>\n",
       "      <td>-0.389908</td>\n",
       "      <td>-0.955745</td>\n",
       "      <td>0.363194</td>\n",
       "      <td>-0.365785</td>\n",
       "      <td>-0.785781</td>\n",
       "      <td>0.568015</td>\n",
       "      <td>-0.398585</td>\n",
       "      <td>-1.382882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.099338</td>\n",
       "      <td>-0.070405</td>\n",
       "      <td>0.205419</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>-0.094676</td>\n",
       "      <td>-0.174042</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>-0.113713</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139105</td>\n",
       "      <td>0.121489</td>\n",
       "      <td>-0.314922</td>\n",
       "      <td>-0.749870</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.446836</td>\n",
       "      <td>0.585836</td>\n",
       "      <td>-0.167706</td>\n",
       "      <td>-0.535036</td>\n",
       "      <td>-0.329375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.099338</td>\n",
       "      <td>-0.070405</td>\n",
       "      <td>0.205419</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>-0.094676</td>\n",
       "      <td>-0.174042</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>-0.113713</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365643</td>\n",
       "      <td>0.525222</td>\n",
       "      <td>-0.957646</td>\n",
       "      <td>-0.273346</td>\n",
       "      <td>0.590983</td>\n",
       "      <td>-0.222378</td>\n",
       "      <td>0.295192</td>\n",
       "      <td>0.700046</td>\n",
       "      <td>-0.311182</td>\n",
       "      <td>-0.250202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.083170 -0.043354  0.076106  0.040648 -0.037274 -0.071351  0.074718   \n",
       "1 -0.099338 -0.070405  0.205419  0.216334 -0.094676 -0.174042  0.145519   \n",
       "2 -0.099338 -0.070405  0.205419  0.216334 -0.094676 -0.174042  0.145519   \n",
       "3 -0.099338 -0.070405  0.205419  0.216334 -0.094676 -0.174042  0.145519   \n",
       "4 -0.099338 -0.070405  0.205419  0.216334 -0.094676 -0.174042  0.145519   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.100185 -0.035602 -0.064168  ... -0.109340  0.252012 -0.828429  0.283238   \n",
       "1  0.111455 -0.113713 -0.084562  ...  0.186319 -0.279245 -0.044980  0.132863   \n",
       "2  0.111455 -0.113713 -0.084562  ... -0.356585 -0.104044 -0.389908 -0.955745   \n",
       "3  0.111455 -0.113713 -0.084562  ... -0.139105  0.121489 -0.314922 -0.749870   \n",
       "4  0.111455 -0.113713 -0.084562  ...  0.365643  0.525222 -0.957646 -0.273346   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.844313 -0.335749  0.259507  0.261004  0.393101 -0.043140  \n",
       "1  0.008049 -0.043891  0.665636 -0.470371 -0.014240  0.328362  \n",
       "2  0.363194 -0.365785 -0.785781  0.568015 -0.398585 -1.382882  \n",
       "3  0.022310  0.446836  0.585836 -0.167706 -0.535036 -0.329375  \n",
       "4  0.590983 -0.222378  0.295192  0.700046 -0.311182 -0.250202  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  3\n",
       "1  4\n",
       "2  4\n",
       "3  5\n",
       "4  4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's fit a baseline model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_X, df_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_split=5,\n",
    "                           max_leaf_nodes=10)\n",
    "\n",
    "\n",
    "dtm_fit = dtm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2012281479689864"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "y_pred = dtm.predict(X_test)\n",
    "mean_squared_error(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[100])\n",
    "input_B = keras.layers.Input(shape=[100])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 418959 samples\n",
      "Epoch 1/20\n",
      "418959/418959 [==============================] - 34s 81us/sample - loss: 1.2257\n",
      "Epoch 2/20\n",
      "418959/418959 [==============================] - 32s 78us/sample - loss: 1.1556\n",
      "Epoch 3/20\n",
      "418959/418959 [==============================] - 32s 76us/sample - loss: 1.1447\n",
      "Epoch 4/20\n",
      "418959/418959 [==============================] - 32s 76us/sample - loss: 1.1383\n",
      "Epoch 5/20\n",
      "418959/418959 [==============================] - 32s 76us/sample - loss: 1.1345\n",
      "Epoch 6/20\n",
      "418959/418959 [==============================] - 32s 76us/sample - loss: 1.1310\n",
      "Epoch 7/20\n",
      "418959/418959 [==============================] - 32s 76us/sample - loss: 1.1279\n",
      "Epoch 8/20\n",
      "418959/418959 [==============================] - 32s 77us/sample - loss: 1.1257\n",
      "Epoch 9/20\n",
      "418959/418959 [==============================] - 32s 77us/sample - loss: 1.1237\n",
      "Epoch 10/20\n",
      "418959/418959 [==============================] - 32s 77us/sample - loss: 1.1212\n",
      "Epoch 11/20\n",
      "418959/418959 [==============================] - 32s 77us/sample - loss: 1.1196\n",
      "Epoch 12/20\n",
      "418959/418959 [==============================] - 32s 76us/sample - loss: 1.1186\n",
      "Epoch 13/20\n",
      "418959/418959 [==============================] - 32s 78us/sample - loss: 1.1171\n",
      "Epoch 14/20\n",
      "418959/418959 [==============================] - 33s 80us/sample - loss: 1.1159\n",
      "Epoch 15/20\n",
      "418959/418959 [==============================] - 34s 81us/sample - loss: 1.1152\n",
      "Epoch 16/20\n",
      "418959/418959 [==============================] - 35s 83us/sample - loss: 1.1135\n",
      "Epoch 17/20\n",
      "418959/418959 [==============================] - 34s 82us/sample - loss: 1.1131\n",
      "Epoch 18/20\n",
      "418959/418959 [==============================] - 34s 81us/sample - loss: 1.1121\n",
      "Epoch 19/20\n",
      "418959/418959 [==============================] - 34s 81us/sample - loss: 1.1114\n",
      "Epoch 20/20\n",
      "418959/418959 [==============================] - 34s 81us/sample - loss: 1.1107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x171fdb21b88>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( (X_train.values[:,:100], X_train.values[:,100:]),Y_train.values, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test.values[:,:100], X_test.values[:,100:]), Y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1363714801461637\n"
     ]
    }
   ],
   "source": [
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's design another structure which includes a dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[100]) #user embedding\n",
    "input_B = keras.layers.Input(shape=[100]) #book embedding\n",
    "hidden1 = keras.layers.Dense(50, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(50, activation=\"relu\")(hidden1)\n",
    "multiple = keras.layers.Multiply()([input_A, input_B]) \n",
    "#this will perform elementwise multiplicatiion, note if we add them together then this is a dot product\n",
    "hidden_multi = keras.layers.Dense(50, activation='relu')(multiple)\n",
    "concat = keras.layers.concatenate([input_A, hidden2,hidden_multi])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 418959 samples\n",
      "Epoch 1/20\n",
      "418959/418959 [==============================] - 37s 89us/sample - loss: 1.2051\n",
      "Epoch 2/20\n",
      "418959/418959 [==============================] - 38s 90us/sample - loss: 1.1406\n",
      "Epoch 3/20\n",
      "418959/418959 [==============================] - 37s 87us/sample - loss: 1.1266\n",
      "Epoch 4/20\n",
      "418959/418959 [==============================] - 37s 88us/sample - loss: 1.1164\n",
      "Epoch 5/20\n",
      "418959/418959 [==============================] - 37s 88us/sample - loss: 1.1091\n",
      "Epoch 6/20\n",
      "418959/418959 [==============================] - 36s 87us/sample - loss: 1.1038\n",
      "Epoch 7/20\n",
      "418959/418959 [==============================] - 38s 90us/sample - loss: 1.0986\n",
      "Epoch 8/20\n",
      "418959/418959 [==============================] - 36s 87us/sample - loss: 1.0943\n",
      "Epoch 9/20\n",
      "418959/418959 [==============================] - 37s 87us/sample - loss: 1.0903\n",
      "Epoch 10/20\n",
      "418959/418959 [==============================] - 37s 87us/sample - loss: 1.0868\n",
      "Epoch 11/20\n",
      "418959/418959 [==============================] - 36s 87us/sample - loss: 1.0836\n",
      "Epoch 12/20\n",
      "418959/418959 [==============================] - 37s 87us/sample - loss: 1.0808\n",
      "Epoch 13/20\n",
      "418959/418959 [==============================] - 38s 91us/sample - loss: 1.0779\n",
      "Epoch 14/20\n",
      "418959/418959 [==============================] - 42s 100us/sample - loss: 1.0760\n",
      "Epoch 15/20\n",
      "418959/418959 [==============================] - 43s 104us/sample - loss: 1.0737\n",
      "Epoch 16/20\n",
      "418959/418959 [==============================] - 41s 99us/sample - loss: 1.0715\n",
      "Epoch 17/20\n",
      "418959/418959 [==============================] - 38s 91us/sample - loss: 1.0700\n",
      "Epoch 18/20\n",
      "418959/418959 [==============================] - 39s 92us/sample - loss: 1.0685\n",
      "Epoch 19/20\n",
      "418959/418959 [==============================] - 37s 89us/sample - loss: 1.0671\n",
      "Epoch 20/20\n",
      "418959/418959 [==============================] - 38s 90us/sample - loss: 1.0656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x171fdf6fd48>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( (X_train.values[:,:100], X_train.values[:,100:]),Y_train.values, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test.values[:,:100], X_test.values[:,100:]), Y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1229772819597712"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
