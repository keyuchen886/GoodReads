{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let matrix M be the matrix we want to decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../glove_data/glove.6B/glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0872530af6d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the whole embedding into memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../glove_data/glove.6B/glove.6B.100d.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../glove_data/glove.6B/glove.6B.100d.txt'"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('../glove_data/glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding = Embedding( vocab_size, 100, input_length=1  )\n",
    "model.add(embedding)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = array(  [  [1] , [2],[3],[4] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = array( [    [0,0,0,1,0], [0,0,1,0,0], [0,1,0,0,0], [0,0,0,0,1]   ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39590773, 0.37309825, 0.39334664, 0.55541867, 0.3881981 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([ 3.57007124e-02, -2.32096445e-02, -4.90398295e-02,  1.47134699e-02,\n",
       "       -6.58601522e-03, -6.82646036e-03, -4.07556891e-02,  1.10339895e-02,\n",
       "        4.64746691e-02,  3.33900340e-02,  2.55318545e-02,  1.15167275e-02,\n",
       "        3.41591127e-02, -2.42596269e-02, -4.00106423e-02, -3.22442651e-02,\n",
       "        2.57013775e-02, -4.84557748e-02, -2.69672405e-02,  2.56438293e-02,\n",
       "       -9.01168585e-03, -2.10463405e-02,  3.97637598e-02, -4.70981859e-02,\n",
       "        2.36223452e-02,  1.88614242e-02, -5.59785217e-03,  4.35889699e-02,\n",
       "       -3.63927707e-02, -9.49269533e-03, -4.98044491e-02,  2.56957524e-02,\n",
       "        1.58254616e-02,  1.21947639e-02, -3.31111923e-02, -3.36569548e-02,\n",
       "       -4.50991169e-02,  3.51453908e-02,  1.69365890e-02, -8.74400139e-05,\n",
       "       -1.48037672e-02,  3.88452150e-02, -1.19431131e-02,  2.39114836e-03,\n",
       "       -3.40183601e-02, -4.57908176e-02, -3.72370705e-02, -2.96023618e-02,\n",
       "       -4.81208675e-02, -2.01481711e-02,  3.05191316e-02,  2.26235390e-03,\n",
       "       -9.61874798e-03,  9.52363014e-03, -3.41344625e-04,  3.29861082e-02,\n",
       "       -1.76462755e-02, -4.62751761e-02,  4.30322327e-02, -2.40842942e-02,\n",
       "       -3.99649739e-02, -2.07520127e-02,  4.18867357e-02, -1.91175230e-02,\n",
       "        4.45297845e-02,  9.23358276e-03,  2.88019329e-03,  1.65204071e-02,\n",
       "        1.91856660e-02,  1.62878744e-02, -1.82555988e-03, -7.04585388e-03,\n",
       "        9.72704962e-03,  8.64978880e-03, -1.09372288e-03,  8.67955759e-03,\n",
       "        4.61430885e-02,  3.82832326e-02, -4.30493243e-02, -2.34201197e-02,\n",
       "       -3.82580645e-02, -9.31908935e-03, -4.17662859e-02, -3.05065513e-02,\n",
       "       -3.73798013e-02, -7.05990940e-03, -2.38396525e-02, -8.31934065e-03,\n",
       "        3.32279131e-03, -4.56432104e-02,  6.11551851e-03, -6.61132485e-03,\n",
       "        1.50875710e-02, -3.29944491e-02,  4.50751521e-02, -3.59389894e-02,\n",
       "        3.71871330e-02,  2.96856202e-02,  3.41067649e-02, -1.07337832e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14087\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.6789\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 0us/step - loss: 0.6755\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 259us/step - loss: 0.6721\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 643us/step - loss: 0.6687\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 260us/step - loss: 0.6653\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.6619\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6585\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 632us/step - loss: 0.6551\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 251us/step - loss: 0.6517\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 806us/step - loss: 0.6483\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.6449\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 822us/step - loss: 0.6415\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6381\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 538us/step - loss: 0.6347\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6312\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 551us/step - loss: 0.6278\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6244\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 668us/step - loss: 0.6209\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 522us/step - loss: 0.6175\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 553us/step - loss: 0.6140\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 791us/step - loss: 0.6105\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.6070\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 640us/step - loss: 0.6035\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 764us/step - loss: 0.6000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 454us/step - loss: 0.5964\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 626us/step - loss: 0.5928\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 778us/step - loss: 0.5892\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 618us/step - loss: 0.5856\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 577us/step - loss: 0.5820\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.5784\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.5747\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 0us/step - loss: 0.5710\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 693us/step - loss: 0.5673\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 385us/step - loss: 0.5635\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 569us/step - loss: 0.5598\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.5560\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 542us/step - loss: 0.5522\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5484\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 485us/step - loss: 0.5445\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5406\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 395us/step - loss: 0.5367\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5328\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 963us/step - loss: 0.5289\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 436us/step - loss: 0.5249\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5210\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 965us/step - loss: 0.5170\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 0us/step - loss: 0.5129\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 770us/step - loss: 0.5089\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5049\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 707us/step - loss: 0.5008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18acaeb0a58>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "model.fit(train_x,train_y,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
